#!/usr/bin/env python3
import requests
import json
import os
import time
from urllib.parse import urlparse
from bs4 import BeautifulSoup

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò–ó SECRETS ---
BASE_URL = os.getenv("FRESHRSS_URL", "").rstrip('/')
USER = os.getenv("FRESHRSS_USER")
PASS = os.getenv("FRESHRSS_PASS")
OPENROUTER_KEY = os.getenv("OPENROUTER_KEY")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")

# –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
CATEGORIES_AI = [c.strip() for c in os.getenv("CATEGORIES_AI", "").split(",") if c.strip()]
CATEGORIES_DIRECT = [c.strip() for c in os.getenv("CATEGORIES_DIRECT", "").split(",") if c.strip()]

AI_MODELS = [
    "google/gemini-2.0-flash-001",
    "google/gemini-2.0-flash-exp:free",
    "qwen/qwen-2.5-72b-instruct"
]

def log(message):
    print(f"[{time.strftime('%H:%M:%S')}] {message}")

def get_auth_token():
    url = f"{BASE_URL}/api/greader.php/accounts/ClientLogin"
    try:
        r = requests.get(url, params={'Email': USER, 'Passwd': PASS}, timeout=10)
        if r.status_code == 200:
            for line in r.text.split('\n'):
                if line.startswith('Auth='): return line.replace('Auth=', '').strip()
    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
    return None

def get_full_text(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        r = requests.get(url, headers=headers, timeout=12)
        if r.status_code != 200: return ""
        soup = BeautifulSoup(r.text, 'html.parser')
        for s in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'button', 'form']): s.decompose()
        article = (soup.find('div', {'class': 'tm-article-body'}) or soup.find('article') or soup.find('main'))
        text = article.get_text(separator=' ', strip=True) if article else soup.get_text(separator=' ', strip=True)
        return " ".join(text.split())[:5000]
    except: return ""

def get_ai_summary(url, seen_summaries):
    content = get_full_text(url)
    if len(content) < 150: return None

    prompt = (
        "–ù–∞–ø–∏—à–∏ —Å—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –û–î–ù–ò–ú —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º (–¥–æ 30 —Å–ª–æ–≤) –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ. "
        "–û—Ç—Ä–∞–∑–∏ —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–ª–∏ –Ω–∞—É—á–Ω—ã–π —Ñ–∞–∫—Ç. –ò–≥–Ω–æ—Ä–∏—Ä—É–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏. "
        "–ï—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç—å –¥—É–±–ª–∏—Ä—É–µ—Ç —Å–º—ã—Å–ª —ç—Ç–∏—Ö —Ç–µ–º: " + ", ".join(list(seen_summaries)[-5:]) + ", –æ—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–æ–º –î–£–ë–õ–ò–ö–ê–¢. "
        f"\n\n–¢–ï–ö–°–¢ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:\n{content[:4000]}"
    )

    for model in AI_MODELS:
        try:
            log(f"    ü§ñ –ó–∞–ø—Ä–æ—Å –∫ {model.split('/')[-1]}...")
            r = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={"Authorization": f"Bearer {OPENROUTER_KEY}", "Content-Type": "application/json"},
                data=json.dumps({"model": model, "messages": [{"role": "user", "content": prompt}], "temperature": 0.2}),
                timeout=30
            )
            if r.status_code == 200:
                res = r.json()['choices'][0]['message']['content'].strip()
                if "–î–£–ë–õ–ò–ö–ê–¢" in res.upper(): return "SKIP"
                return res.rstrip('.')
        except: continue
    return None

def extract_hashtag(url):
    try:
        domain = urlparse(url).netloc.lower()
        parts = domain.replace('www.', '').split('.')
        tag = parts[0].replace('-', '')
        return f"#{tag}"
    except: return "#news"

def process_category(cat_name, use_ai, token, headers, api_base, global_seen):
    log(f"--- –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {cat_name} (–ò–ò: {use_ai}) ---")
    try:
        r = requests.get(f"{api_base}/stream/contents/user/-/label/{cat_name}",
                         params={'xt': 'user/-/state/com.google/read', 'n': 10}, headers=headers)
        if r.status_code != 200:
            log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {r.status_code}")
            return

        items = r.json().get('items', [])
        if not items:
            log("  –ù–µ—Ç –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π.")
            return

        ai_msg_body = f"<b>{cat_name.upper()}:</b>\n\n"
        ai_count = 0

        for item in items:
            title = item.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
            link = item.get('alternate', [{}])[0].get('href', '')
            tag = extract_hashtag(link)

            if use_ai:
                log(f"üëâ –ê–Ω–∞–ª–∏–∑: {title[:50]}...")
                summary = get_ai_summary(link, global_seen)
                if summary == "SKIP":
                    log("    üö´ –î—É–±–ª–∏–∫–∞—Ç. –ü—Ä–æ–ø—É—Å–∫.")
                else:
                    text = summary if summary else title
                    ai_msg_body += f"üìå {text} üîó <a href='{link}'>{tag}</a>\n\n"
                    global_seen.add(text)
                    ai_count += 1
            else:
                # DIRECT (YouTube): –ø–æ –æ–¥–Ω–æ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é –¥–ª—è –ø—Ä–µ–≤—å—é
                log(f"üìΩ –û—Ç–ø—Ä–∞–≤–∫–∞ –≤–∏–¥–µ–æ: {title[:50]}...")
                direct_msg = f"{link}\n\nüìΩ <b>{title}</b> {tag}"
                requests.post(f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
                              data={"chat_id": CHAT_ID, "text": direct_msg, "parse_mode": "HTML",
                                    "disable_web_page_preview": False})

            # –ü–æ–º–µ—á–∞–µ–º –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–º –≤–æ FreshRSS
            requests.post(f"{api_base}/edit-tag", headers=headers, data={'i': item.get('id'), 'a': 'user/-/state/com.google/read'})

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–∞—á–∫—É –ò–ò-–Ω–æ–≤–æ—Å—Ç–µ–π –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        if use_ai and ai_count > 0:
            requests.post(f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
                          data={"chat_id": CHAT_ID, "text": ai_msg_body, "parse_mode": "HTML",
                                "disable_web_page_preview": True})
            log(f"‚úÖ –°–≤–æ–¥–∫–∞ –ò–ò –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞.")

    except Exception as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {cat_name}: {e}")

def main():
    log("=== –ó–ê–ü–£–°–ö –ë–û–¢–ê ===")
    token = get_auth_token()
    if not token: return

    headers = {'Authorization': f'GoogleLogin auth={token}'}
    api_base = f"{BASE_URL}/api/greader.php/reader/api/0"
    global_seen = set()

    # –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ò–ò –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    for cat in CATEGORIES_AI:
        process_category(cat, True, token, headers, api_base, global_seen)

    # –ó–∞—Ç–µ–º YouTube/–í–∏–¥–µ–æ
    for cat in CATEGORIES_DIRECT:
        process_category(cat, False, token, headers, api_base, global_seen)

    log("=== –†–ê–ë–û–¢–ê –ó–ê–í–ï–†–®–ï–ù–ê ===")

if __name__ == "__main__":
    main()
