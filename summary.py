#!/usr/bin/env python3
import requests
import json
import os
import time
import re
from urllib.parse import urlparse
from bs4 import BeautifulSoup

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
BASE_URL = os.getenv("FRESHRSS_URL", "").rstrip('/')
USER = os.getenv("FRESHRSS_USER")
PASS = os.getenv("FRESHRSS_PASS")
OPENROUTER_KEY = os.getenv("OPENROUTER_KEY")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")
CATEGORIES_AI = [c.strip() for c in os.getenv("CATEGORIES_AI", "").split(",") if c.strip()]
CATEGORIES_DIRECT = [c.strip() for c in os.getenv("CATEGORIES_DIRECT", "").split(",") if c.strip()]

# –°–ø–∏—Å–æ–∫ —Ä–µ–∞–ª—å–Ω–æ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤ (Round-robin)
AI_MODELS = [
    "meta-llama/llama-3.1-405b-instruct:free",
    "nousresearch/hermes-3-llama-3.1-405b:free",
    "qwen/qwen-2.5-vl-7b-instruct:free",
    "meta-llama/llama-3.2-3b-instruct:free",
    "google/gemma-3-27b-it:free",
    "mistralai/mistral-small-3.1-24b-instruct:free",
    "qwen/qwen3-4b:free",
    "openai/gpt-oss-20b:free"
]

model_index = 0
processed_summaries = []

def log(message):
    print(f"[{time.strftime('%H:%M:%S')}] {message}")

def get_ai_summary(text, is_video):
    global model_index
    if not text or len(text) < 100: return None

    # –û—Å–ª–∞–±–∏–ª–∏ —Ñ–∏–ª—å—Ç—Ä: –ò–ò —Ç–µ–ø–µ—Ä—å –∑–Ω–∞–µ—Ç –ø—Ä–æ "—Å–µ—Ä–∏–∏" –ø–æ—Å—Ç–æ–≤
    context = "\n".join(processed_summaries[-6:])
    prompt = (
        f"–¢—ã ‚Äî –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫. –ù–∞–ø–∏—à–∏ —Å—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –û–î–ù–ò–ú –∫–æ—Ä–æ—Ç–∫–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º ( 30 —Å–ª–æ–≤) –Ω–∞ —Ä—É—Å—Å–∫–æ–º.\n"
        f"–ü–†–ê–í–ò–õ–û SKIP: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û —Å–ª–æ–≤–æ–º SKIP, –µ—Å–ª–∏ —ç—Ç–æ –∞–±—Å–æ–ª—é—Ç–Ω—ã–π –¥—É–±–ª–∏–∫–∞—Ç –ø–æ —Å–º—ã—Å–ª—É (–æ–¥–Ω–æ –∏ —Ç–æ –∂–µ —Å–æ–±—ã—Ç–∏–µ).\n"
        f"–í–ê–ñ–ù–û: –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç–µ–º—ã, –Ω–æ–≤–∞—è —á–∞—Å—Ç—å —Å–µ—Ä–∏–∏ –ø–æ—Å—Ç–æ–≤ –∏–ª–∏ –¥—Ä—É–≥–æ–π –∞—Å–ø–µ–∫—Ç –Ω–æ–≤–æ—Å—Ç–∏ ‚Äî –ü–ò–®–ò —Å–≤–æ–¥–∫—É. –ù–µ —Å–∫–∏–ø–∞–π JamClub –∏ —Å–µ—Ä–∏–π–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏.\n"
        f"–†–∞–Ω–µ–µ –±—ã–ª–æ: {context}\n–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {text}"
    )

    # –ö—Ä—É—Ç–∏–º –∫–∞—Ä—É—Å–µ–ª—å –º–æ–¥–µ–ª–µ–π
    for _ in range(len(AI_MODELS)):
        model = AI_MODELS[model_index % len(AI_MODELS)]
        model_index += 1

        try:
            r = requests.post("https://openrouter.ai/api/v1/chat/completions",
                headers={"Authorization": f"Bearer {OPENROUTER_KEY}", "Content-Type": "application/json"},
                data=json.dumps({"model": model, "messages": [{"role": "user", "content": prompt}], "temperature": 0.4}), timeout=25)

            if r.status_code == 200:
                res = r.json()['choices'][0]['message']['content'].strip().rstrip('.')
                if "SKIP" in res.upper() and len(res) < 10: return "SKIP"

                final = f"{res} üé¨" if is_video and "üé¨" not in res else res
                processed_summaries.append(final)
                log(f"‚úÖ {model.split('/')[-1]} –≤—ã–¥–∞–ª –±–∞–∑—É")
                return final
            else:
                log(f"‚ö†Ô∏è {model.split('/')[-1]} —Å—Ç–∞—Ç—É—Å {r.status_code}")
        except Exception as e:
            log(f"‚ùå {model.split('/')[-1]} —Å–±–æ–π")
            continue
    return None

def get_content(url):
    try:
        r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=12)
        soup = BeautifulSoup(r.text, 'html.parser')
        # –ò—â–µ–º —Å—É—Ç—å —Å—Ç–∞—Ç—å–∏, –æ—Ç—Å–µ–∫–∞—è –ª–∏—à–Ω–µ–µ
        article = soup.find('div', {'class': ['tgme_widget_message_text', 'article-body', 'post__text']}) or soup.find('article')
        text = article.get_text(separator=' ', strip=True) if article else soup.get_text(separator=' ', strip=True)
        return " ".join(text.split())[:3500], soup
    except: return "", None

def process_category(cat_name, use_ai, headers, api_base):
    log(f"--- üìÇ –ö–ê–¢–ï–ì–û–†–ò–Ø: {cat_name.upper()} ---")
    r = requests.get(f"{api_base}/stream/contents/user/-/label/{cat_name}", params={'n': 50, 'xt': 'user/-/state/com.google/read'}, headers=headers)
    items = r.json().get('items', [])
    if not items:
        log("‚òï –ù–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ—Ç")
        return

    valid_news = []
    for item in items:
        link = item.get('alternate', [{}])[0].get('href', '')
        if not link: continue

        text, soup = get_content(link)
        is_video = any(x in link.lower() for x in ["youtube.com", "youtu.be"]) or (soup and soup.find('video'))

        if use_ai:
            summary = get_ai_summary(text, is_video)
            if summary == "SKIP":
                log(f"‚è≠Ô∏è SKIP: –î—É–±–ª–∏–∫–∞—Ç ({link[:35]}...)")
            elif summary:
                valid_news.append({"link": link, "content": summary, "id": item.get('id')})
            time.sleep(1.5) # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –ò–ò
        else:
            # –ü—Ä—è–º–∞—è –ø–µ—Ä–µ—Å—ã–ª–∫–∞ –¥–ª—è CATEGORIES_DIRECT
            msg = f"üìç <b><a href='{link}'>{item.get('title')}</a></b>"
            if is_video: time.sleep(15) # –ü–∞—É–∑–∞ –¥–ª—è –ø—Ä–æ–≥—Ä—É–∑–∫–∏ –ø—Ä–µ–≤—å—é –≤–∏–¥–µ–æ
            if send_tg(msg, True, link):
                mark_as_read(api_base, headers, item.get('id'))
                log(f"üöÄ –ü—Ä—è–º–æ–π –ø–æ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {link[:40]}")

    if use_ai and valid_news:
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º
        valid_news.reverse()
        msg = f"#{cat_name}\n\n" + "\n\n".join([f"üìå <a href='{n['link']}'>‚Üí</a> <i>{n['content']}</i>" for n in valid_news])
        if send_tg(msg):
            for n in valid_news: mark_as_read(api_base, headers, n['id'])
            log(f"‚úÖ –°–≤–æ–¥–∫–∞ {cat_name} —É–ª–µ—Ç–µ–ª–∞ –≤ Telegram")

def send_tg(text, preview=False, link=None):
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    opts = {"is_disabled": not preview}
    if preview and link: opts.update({"url": link, "prefer_large_media": True})
    payload = {"chat_id": CHAT_ID, "text": text, "parse_mode": "HTML", "link_preview_options": json.dumps(opts)}
    try:
        res = requests.post(url, data=payload, timeout=15)
        return res.status_code == 200
    except: return False

def mark_as_read(api_base, headers, item_id):
    requests.post(f"{api_base}/edit-tag", headers=headers, data={'i': item_id, 'a': 'user/-/state/com.google/read'})

def main():
    auth_res = requests.get(f"{BASE_URL}/api/greader.php/accounts/ClientLogin?Email={USER}&Passwd={PASS}")
    auth = re.search(r'Auth=(.*)', auth_res.text)
    if not auth:
        log("‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")
        return
    headers = {'Authorization': f'GoogleLogin auth={auth.group(1).strip()}'}
    api_base = f"{BASE_URL}/api/greader.php/reader/api/0"

    for cat in CATEGORIES_AI: process_category(cat, True, headers, api_base)
    for cat in CATEGORIES_DIRECT: process_category(cat, False, headers, api_base)

if __name__ == "__main__": main()
