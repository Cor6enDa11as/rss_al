#!/usr/bin/env python3

import requests
import json
import os
import time
import re
from urllib.parse import urlparse, urlunparse
from bs4 import BeautifulSoup

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
BASE_URL = os.getenv("FRESHRSS_URL", "").rstrip('/')
USER = os.getenv("FRESHRSS_USER")
PASS = os.getenv("FRESHRSS_PASS")
OPENROUTER_KEY = os.getenv("OPENROUTER_KEY")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")
CATEGORIES_AI = [c.strip() for c in os.getenv("CATEGORIES_AI", "").split(",") if c.strip()]
CATEGORIES_DIRECT = [c.strip() for c in os.getenv("CATEGORIES_DIRECT", "").split(",") if c.strip()]

DB_FILE = "seen_urls.txt"
AI_MODELS = ["google/gemini-2.0-flash-lite-001", "google/gemini-2.0-flash-001"]

def log(message):
    print(f"[{time.strftime('%H:%M:%S')}] {message}")

def normalize_url(url):
    try:
        parsed = urlparse(url)
        return urlunparse((parsed.scheme, parsed.netloc, parsed.path, '', '', ''))
    except: return url

def make_hashtag(text):
    clean = re.sub(r'[^a-zA-Z–∞-—è–ê-–Ø—ë–Å0-9]', '', text)
    return f"#{clean}" if clean else ""

def get_smart_tag(item, url):
    source_name = item.get('origin', {}).get('title', '')
    if "telegram channel" in source_name.lower():
        clean_text = re.sub(r'(?i)\s*[-]*\s*(telegram\s*channel)\s*', '', source_name).strip()
        return make_hashtag(clean_text)
    try:
        domain = urlparse(url).netloc.lower()
        tag = domain.replace('www.', '').split('.')[0].replace('-', '')
        return f"#{tag.capitalize()}"
    except: return "#News"

def check_is_video_strict(item, soup):
    link = item.get('alternate', [{}])[0].get('href', '').lower()
    # –î–ª—è YouTube –≤–æ–∑–≤—Ä–∞—â–∞–µ–º True, –Ω–æ –ø–æ–º–µ—Ç–∫—É —Ç–µ–∫—Å—Ç–æ–º —É–±–µ—Ä–µ–º –ø–æ–∑–∂–µ
    if any(x in link for x in ["youtube.com", "youtu.be", "vimeo.com"]): return True
    if "–≤–∏–¥–µ–æ" in item.get('title', '').lower(): return True
    if soup and (soup.find('video') or soup.find('iframe', src=re.compile(r'video|youtube|player')) or soup.find('div', class_='tgme_widget_message_video_player')):
        return True
    return False

def get_full_content(item, url):
    try:
        r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=12)
        soup = BeautifulSoup(r.text, 'html.parser')
        article = (soup.find('div', {'class': 'tgme_widget_message_text'}) or
                   soup.find('div', {'class': 'tm-article-body'}) or
                   soup.find('article'))
        if article: return " ".join(article.get_text(separator=' ', strip=True).split())[:3500], soup
        rss_text = item.get('summary', {}).get('content', '') or item.get('content', {}).get('content', '')
        if rss_text:
            clean_rss = BeautifulSoup(rss_text, 'html.parser').get_text(separator=' ', strip=True)
            return clean_rss[:3500], soup
    except Exception as e: log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
    return "", None

def get_ai_summary(text, is_video=False):
    if not text or len(text) < 100: return None
    prompt = "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Å—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –û–î–ù–ò–ú –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º (–¥–æ 30 —Å–ª–æ–≤) –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –û–ø–∏—à–∏ —Å–æ–±—ã—Ç–∏–µ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç."
    for model in AI_MODELS:
        try:
            r = requests.post("https://openrouter.ai/api/v1/chat/completions",
                headers={"Authorization": f"Bearer {OPENROUTER_KEY}", "Content-Type": "application/json"},
                data=json.dumps({"model": model, "messages": [{"role": "user", "content": f"{prompt}\n\n{text}"}], "temperature": 0.1}), timeout=30)
            if r.status_code == 200:
                res = r.json()['choices'][0]['message']['content'].strip().rstrip('.')
                if is_video and "(–í–∏–¥–µ–æ)" not in res: res += " (–í–∏–¥–µ–æ)"
                log(f"‚úÖ –ú–æ–¥–µ–ª—å {model} —É—Å–ø–µ—à–Ω–æ —Å—Ä–∞–±–æ—Ç–∞–ª–∞.")
                return res
        except: continue
    return None

def send_tg(text, preview_enabled=False, link=None):
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    p_opts = {"is_disabled": not preview_enabled}
    if preview_enabled and link: p_opts.update({"url": link, "prefer_large_media": True, "show_above_text": True})
    payload = {"chat_id": CHAT_ID, "text": text, "parse_mode": "HTML", "link_preview_options": json.dumps(p_opts)}
    try: requests.post(url, data=payload, timeout=10)
    except: log("‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ TG")

def process_category(cat_name, use_ai, headers, api_base, global_seen_urls):
    log(f"\n--- {cat_name.upper()} ---")
    try:
        r = requests.get(f"{api_base}/stream/contents/user/-/label/{cat_name}", params={'n': 40}, headers=headers)
        items = r.json().get('items', [])
        if not items: return
        msg_body_ai = f"{make_hashtag(cat_name)}\n\n"
        ai_count = 0
        for item in items:
            link = item.get('alternate', [{}])[0].get('href', '')
            if not link or link in global_seen_urls: continue
            text_content, soup = get_full_content(item, link)
            is_video = check_is_video_strict(item, soup)
            is_youtube = any(x in link.lower() for x in ["youtube.com", "youtu.be"])
            tag = get_smart_tag(item, link)
            if use_ai:
                summary = get_ai_summary(text_content, is_video) or item.get('title', '–ù–æ–≤–æ—Å—Ç—å')
                if is_video and "(–í–∏–¥–µ–æ)" not in summary: summary += " (–í–∏–¥–µ–æ)"
                msg_body_ai += f"üìå <a href='{link}'>‚Üí</a> <i>{summary}</i>\nüè∑Ô∏è {tag}\n\n"
                ai_count += 1
                time.sleep(1)
            else:
                # DIRECT (YouTube)
                title = item.get('title', '–í–∏–¥–µ–æ')
                # –î–ª—è YouTube –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º (–í–∏–¥–µ–æ) —Ç–µ–∫—Å—Ç–æ–º, –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–µ–ª–∞–µ–º —Å—Å—ã–ª–∫–æ–π
                if is_youtube:
                    direct_msg = f"üìç <b><a href='{link}'>{title}</a></b>\nüè∑Ô∏è {tag}"
                    log(f"‚è≥ –ü–∞—É–∑–∞ 3—Å –¥–ª—è –ø—Ä–µ–≤—å—é YouTube...")
                    time.sleep(10) # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–≤—å—é
                else:
                    title_text = f"{title} (–í–∏–¥–µ–æ)" if is_video else title
                    direct_msg = f"üìç <b><a href='{link}'>{title_text}</a></b>\nüè∑Ô∏è {tag}"
                send_tg(direct_msg, True, link)
                log(f"‚úÖ Direct: {tag}")
            global_seen_urls.add(link)
            requests.post(f"{api_base}/edit-tag", headers=headers, data={'i': item.get('id'), 'a': 'user/-/state/com.google/read'})
        if use_ai and ai_count > 0: send_tg(msg_body_ai, False)
    except Exception as e: log(f"‚ùå –û—à–∏–±–∫–∞: {e}")

def main():
    r_auth = requests.get(f"{BASE_URL}/api/greader.php/accounts/ClientLogin?Email={USER}&Passwd={PASS}")
    auth = re.search(r'Auth=(.*)', r_auth.text)
    if not auth: return
    headers = {'Authorization': f'GoogleLogin auth={auth.group(1).strip()}'}
    api_base = f"{BASE_URL}/api/greader.php/reader/api/0"
    seen = set()
    if os.path.exists(DB_FILE):
        with open(DB_FILE, "r") as f: seen = set(line.strip() for line in f)
    for cat in CATEGORIES_AI: process_category(cat, True, headers, api_base, seen)
    for cat in CATEGORIES_DIRECT: process_category(cat, False, headers, api_base, seen)
    with open(DB_FILE, "w") as f:
        for item in list(seen)[-1000:]: f.write(f"{item}\n")

if __name__ == "__main__": main()
