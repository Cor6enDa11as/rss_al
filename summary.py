#!/usr/bin/env python3

import requests
import os
import time
import re
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
BASE_URL = os.getenv("FRESHRSS_URL", "").rstrip('/')
USER = os.getenv("FRESHRSS_USER")
PASS = os.getenv("FRESHRSS_PASS")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")
CATEGORIES_AI = [c.strip() for c in os.getenv("CATEGORIES_AI", "").split(",") if c.strip()]
CATEGORIES_DIRECT = [c.strip() for c in os.getenv("CATEGORIES_DIRECT", "").split(",") if c.strip()]

KEYS = {
    "groq": os.getenv("GROQ_API_KEY"),
    "mistral": os.getenv("MISTRAL_API_KEY"),
    "cohere": os.getenv("COHERE_API_KEY")
}

def log(message):
    print(f"[{time.strftime('%H:%M:%S')}] {message}")

def clean_ai_text(text):
    if not text: return ""
    text = text.replace("**", "")
    # –£–¥–∞–ª—è–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤ (–ø—Ä–æ—Å—å–±–∞ –∏–∑ –ø–∞–º—è—Ç–∏)
    text = re.sub(r"\(?\d+\s*—Å–ª–æ–≤\)?", "", text, flags=re.IGNORECASE)
    return text.strip()

def call_ai(api_name, text):
    prompt = f"–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –≥–ª–∞–≤–Ω—É—é –Ω–æ–≤–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –æ–¥–Ω–∏–º —ë–º–∫–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ (30 —Å–ª–æ–≤). –ü–µ—Ä–µ–¥–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∏–∑–±–µ–≥–∞—è –æ–±—â–∏—Ö —Ñ—Ä–∞–∑. –ó–∞–ø—Ä–µ—â–µ–Ω–æ: Markdown, —Å–∫–æ–±–∫–∏ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–ª–æ–≤, –≤–≤–æ–¥–Ω—ã–µ —Ñ—Ä–∞–∑—ã. –¢–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç. –°—Ç–∞—Ç—å—è: {text[:3800]}"
    try:
        res = None
        if api_name == "groq" and KEYS["groq"]:
            r = requests.post("https://api.groq.com/openai/v1/chat/completions",
                headers={"Authorization": f"Bearer {KEYS['groq']}"},
                json={"model": "llama-3.3-70b-versatile", "messages": [{"role": "user", "content": prompt}]}, timeout=25)
            if r.status_code == 200: res = r.json()['choices'][0]['message']['content']
        elif api_name == "mistral" and KEYS["mistral"]:
            r = requests.post("https://api.mistral.ai/v1/chat/completions",
                headers={"Authorization": f"Bearer {KEYS['mistral']}"},
                json={"model": "mistral-small-latest", "messages": [{"role": "user", "content": prompt}]}, timeout=25)
            if r.status_code == 200: res = r.json()['choices'][0]['message']['content']
        elif api_name == "cohere" and KEYS["cohere"]:
            r = requests.post("https://api.cohere.ai/v1/chat", headers={"Authorization": f"Bearer {KEYS['cohere']}"},
                json={"message": prompt, "model": "command-r-plus"}, timeout=25)
            if r.status_code == 200: res = r.json().get('text')

        if res:
            log(f"üì° [{api_name.upper()}] –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω")
            return clean_ai_text(res)
    except Exception as e:
        log(f"‚ùå AI –û—à–∏–±–∫–∞: {str(e)[:50]}")
    return None

def scrape_full_text(url):
    """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ –ø–æ –≤–Ω–µ—à–Ω–µ–π —Å—Å—ã–ª–∫–µ –¥–ª—è –æ–±—ã—á–Ω—ã—Ö —Å–∞–π—Ç–æ–≤"""
    try:
        r = requests.get(url, timeout=15, headers={'User-Agent': 'Mozilla/5.0'})
        if r.status_code != 200: return ""
        soup = BeautifulSoup(r.text, 'html.parser')
        for s in soup(["script", "style", "nav", "header", "footer"]): s.decompose()
        paragraphs = soup.find_all('p')
        text = " ".join([p.get_text() for p in paragraphs])
        return text if len(text) > 100 else ""
    except:
        return ""

def extract_content(item, is_tg, is_yt):
    """–£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
    raw = (item.get('content', {}).get('content') or item.get('summary', {}).get('content') or
           item.get('description') or item.get('title', ""))

    soup = BeautifulSoup(str(raw), "html.parser")

    # –í–∏–¥–µ–æ-–¥–µ—Ç–µ–∫—Ç–æ—Ä (–Ω–µ –¥–ª—è YouTube)
    has_v = False
    if not is_yt:
        has_v = bool(soup.find(['video', 'iframe', 'embed'])) or ".mp4" in str(raw).lower()

    # –î–ª—è Telegram —É–¥–∞–ª—è–µ–º "—à–∞–ø–∫—É" (–ø–µ—Ä–≤—ã–µ —Å—Å—ã–ª–∫–∏ –∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏)
    if is_tg:
        for _ in range(3):
            first = soup.find(['a', 'img'])
            if first: first.decompose()
            else: break

    clean_text = " ".join(soup.get_text(separator=' ').split())

    # –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
    link = item.get('alternate', [{}])[0].get('href', '')
    if is_tg or is_yt:
        return clean_text, has_v, link
    else:
        # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å —Å–∞–π—Ç
        web_text = scrape_full_text(link)
        return (web_text if len(web_text) > len(clean_text) else clean_text), has_v, link

def get_hashtag(feed_title, link, is_tg_yt):
    """–†–∞–∑–¥–µ–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ —Ö—ç—à—Ç–µ–≥–æ–≤"""
    if is_tg_yt:
        # –ò–∑ –ª–µ–Ω—Ç—ã: —Ä–µ–∂–µ–º —Ö–≤–æ—Å—Ç—ã –∏ —Å–∫–æ–±–∫–∏
        name = re.split(r'[-‚Äî(]', feed_title)[0].strip()
    else:
        # –ò–∑ —Å—Å—ã–ª–∫–∏: Androidinsider
        domain = urlparse(link).netloc.lower().replace('www.', '')
        name = domain.split('.')[0].capitalize()

    # –û—á–∏—Å—Ç–∫–∞: –±—É–∫–≤—ã (–≤–∫–ª—é—á–∞—è —ë), —Ü–∏—Ñ—Ä—ã, —Å–ª–∏—Ç–Ω–æ
    clean = "".join(re.findall(r'[a-zA-Z–∞-—è–ê-–Ø—ë–Å0-9]+', name))
    return f"#{clean}"

def process_item(item, api_name, is_ai):
    link = item.get('alternate', [{}])[0].get('href', '')
    feed_title = item.get('origin', {}).get('title', 'Source')
    domain = urlparse(link).netloc.lower()

    is_tg = "t.me" in domain
    is_yt = any(x in domain for x in ["youtube.com", "youtu.be"])

    full_text, has_v, link = extract_content(item, is_tg, is_yt)
    tag = get_hashtag(feed_title, link, (is_tg or is_yt))

    # –í–∏–¥–µ–æ-—ç–º–æ–¥–∑–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ-YT
    v_mark = "üé¨ " if (has_v and not is_yt) else ""

    if is_ai:
        summary = call_ai(api_name, full_text)
        content = summary if summary else item.get('title')
        # –ö—É—Ä—Å–∏–≤ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏
        line = f"üìå <a href='{link}'>‚Üí</a> <i>{content}</i> {v_mark}\nüè∑Ô∏è {tag}"
    else:
        line = f"üìå <a href='{link}'>{item.get('title')}</a>\nüè∑Ô∏è {tag}"

    return {"id": item.get('id'), "line": line, "is_yt": is_yt}

def mark_read(api_base, headers, ids):
    if not ids: return
    try:
        data = [('i', i_id) for i_id in ids]
        data.append(('a', 'user/-/state/com.google/read'))
        requests.post(f"{api_base}/edit-tag", headers=headers, data=data, timeout=20)
    except: pass

def process_category(cat_name, use_ai, headers, api_base):
    log(f"üöÄ –ö–ê–¢–ï–ì–û–†–ò–Ø: {cat_name.upper()}")
    try:
        r = requests.get(f"{api_base}/stream/contents/user/-/label/{cat_name}",
                        params={'n': 50, 'xt': 'user/-/state/com.google/read'}, headers=headers, timeout=20)
        items = r.json().get('items', [])
    except: return

    if not items: return
    final_results = []
    if use_ai:
        active_apis = [a for a in ["groq", "mistral", "cohere"] if KEYS.get(a)]
        chunks = [items[i::len(active_apis)] for i in range(len(active_apis))]
        with ThreadPoolExecutor(max_workers=3) as ex:
            futures = [ex.submit(lambda c, a: [process_item(it, a, True) for it in c], chunks[i], active_apis[i])
                       for i in range(len(chunks)) if chunks[i]]
            for f in as_completed(futures): final_results.extend(f.result())
    else:
        final_results = [process_item(it, "direct", False) for it in items]

    cat_tag = f"#{cat_name.replace(' ', '')}"
    msg = "" if cat_tag.lower() == "#youtube" else f"{cat_tag}\n\n"
    ids_to_mark = []

    for entry in final_results:
        if not use_ai or entry.get('is_yt'):
            if requests.post(f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
                             json={"chat_id": CHAT_ID, "text": entry['line'], "parse_mode": "HTML",
                                   "link_preview_options": {"show_above_text": True}}).status_code == 200:
                mark_read(api_base, headers, [entry['id']])
            continue

        if len(msg) + len(entry['line']) > 4000:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
            if requests.post(url, json={"chat_id": CHAT_ID, "text": msg.strip(), "parse_mode": "HTML", "link_preview_options": {"is_disabled": True}}).status_code == 200:
                mark_read(api_base, headers, ids_to_mark)
            msg, ids_to_mark = f"{cat_tag}\n\n", []

        msg += entry['line'] + "\n\n"
        ids_to_mark.append(entry['id'])

    if ids_to_mark and msg:
        url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
        if requests.post(url, json={"chat_id": CHAT_ID, "text": msg.strip(), "parse_mode": "HTML", "link_preview_options": {"is_disabled": True}}).status_code == 200:
            mark_read(api_base, headers, ids_to_mark)

def main():
    log("üèÅ –ó–ê–ü–£–°–ö")
    try:
        auth_res = requests.get(f"{BASE_URL}/api/greader.php/accounts/ClientLogin?Email={USER}&Passwd={PASS}", timeout=20)
        auth = re.search(r'Auth=(.*)', auth_res.text)
        if not auth: return
        headers = {'Authorization': f'GoogleLogin auth={auth.group(1).strip()}'}
        api_base = f"{BASE_URL}/api/greader.php/reader/api/0"
        for cat in CATEGORIES_AI: process_category(cat, True, headers, api_base)
        for cat in CATEGORIES_DIRECT: process_category(cat, False, headers, api_base)
        log("‚úÖ –ì–û–¢–û–í–û")
    except Exception as e: log(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__": main()
