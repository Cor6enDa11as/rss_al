#!/usr/bin/env python3

import requests
import os
import time
import re
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
BASE_URL = os.getenv("FRESHRSS_URL", "").rstrip('/')
USER = os.getenv("FRESHRSS_USER")
PASS = os.getenv("FRESHRSS_PASS")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")
CATEGORIES_AI = [c.strip() for c in os.getenv("CATEGORIES_AI", "").split(",") if c.strip()]
CATEGORIES_DIRECT = [c.strip() for c in os.getenv("CATEGORIES_DIRECT", "").split(",") if c.strip()]

KEYS = {
    "groq": os.getenv("GROQ_API_KEY"),
    "mistral": os.getenv("MISTRAL_API_KEY"),
    "cohere": os.getenv("COHERE_API_KEY")
}

def log(message):
    print(f"[{time.strftime('%H:%M:%S')}] {message}")

def clean_ai_text(text):
    if not text: return ""
    text = text.replace("**", "")
    text = re.sub(r"\(?\d+\s*—Å–ª–æ–≤\)?", "", text, flags=re.IGNORECASE)
    return text.strip()

def call_ai(api_name, text):
    prompt = f"–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –≥–ª–∞–≤–Ω—É—é –Ω–æ–≤–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –æ–¥–Ω–∏–º —ë–º–∫–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ (30 —Å–ª–æ–≤). –ü–µ—Ä–µ–¥–∞–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∏–∑–±–µ–≥–∞—è –æ–±—â–∏—Ö —Ñ—Ä–∞–∑. –ó–∞–ø—Ä–µ—â–µ–Ω–æ: Markdown, —Å–∫–æ–±–∫–∏ —Å —á–∏—Å–ª–æ–º —Å–ª–æ–≤, –≤–≤–æ–¥–Ω—ã–µ —Ñ—Ä–∞–∑—ã. –¢–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç. –°—Ç–∞—Ç—å—è: {text[:3800]}"
    try:
        res = None
        if api_name == "groq" and KEYS["groq"]:
            r = requests.post("https://api.groq.com/openai/v1/chat/completions",
                headers={"Authorization": f"Bearer {KEYS['groq']}"},
                json={"model": "llama-3.3-70b-versatile", "messages": [{"role": "user", "content": prompt}]}, timeout=25)
            if r.status_code == 200: res = r.json()['choices'][0]['message']['content']
        elif api_name == "mistral" and KEYS["mistral"]:
            r = requests.post("https://api.mistral.ai/v1/chat/completions",
                headers={"Authorization": f"Bearer {KEYS['mistral']}"},
                json={"model": "mistral-small-latest", "messages": [{"role": "user", "content": prompt}]}, timeout=25)
            if r.status_code == 200: res = r.json()['choices'][0]['message']['content']
        elif api_name == "cohere" and KEYS["cohere"]:
            r = requests.post("https://api.cohere.ai/v1/chat", headers={"Authorization": f"Bearer {KEYS['cohere']}"},
                json={"message": prompt, "model": "command-r-plus"}, timeout=25)
            if r.status_code == 200: res = r.json().get('text')
        if res:
            log(f"üì° [{api_name.upper()}] –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω")
            return clean_ai_text(res)
    except Exception as e:
        log(f"‚ùå AI –û—à–∏–±–∫–∞: {str(e)[:50]}")
    return None

def scrape_full_text(url):
    try:
        r = requests.get(url, timeout=15, headers={'User-Agent': 'Mozilla/5.0'})
        if r.status_code != 200: return ""
        soup = BeautifulSoup(r.text, 'html.parser')
        for s in soup(["script", "style", "nav", "header", "footer"]): s.decompose()
        paragraphs = soup.find_all('p')
        text = " ".join([p.get_text() for p in paragraphs])
        return text if len(text) > 100 else ""
    except: return ""

def extract_content(item, is_tg, is_yt):
    # –ü–†–ò–û–†–ò–¢–ï–¢ –î–õ–Ø TG: —Å–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ description, –ø–æ—Ç–æ–º –≤ content
    raw = ""
    if is_tg:
        raw = item.get('description') or item.get('content', {}).get('content') or item.get('summary', {}).get('content')
    else:
        raw = item.get('content', {}).get('content') or item.get('summary', {}).get('content') or item.get('description')

    raw = raw or item.get('title', "")
    soup = BeautifulSoup(str(raw), "html.parser")

    if is_tg:
        # –£–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏ –∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤ –Ω–∞—á–∞–ª–µ –ø–æ—Å—Ç–∞ (–æ–±—ã—á–Ω–æ —ç—Ç–æ –º—É—Å–æ—Ä –ª–µ–Ω—Ç—ã)
        for junk in soup.find_all(['a', 'img'], limit=3):
            junk.decompose()

    has_v = False
    if not is_yt:
        has_v = bool(soup.find(['video', 'iframe', 'embed'])) or ".mp4" in str(raw).lower()

    clean_text = " ".join(soup.get_text(separator=' ').split())
    link = item.get('alternate', [{}])[0].get('href', '')

    if is_tg or is_yt:
        return clean_text, has_v, link
    else:
        web_text = scrape_full_text(link)
        return (web_text if len(web_text) > len(clean_text) else clean_text), has_v, link

def get_hashtag(feed_title, link, is_tg_yt):
    if is_tg_yt:
        # –†–µ–∂–µ–º —Ö–≤–æ—Å—Ç—ã, –Ω–µ –ª–æ–º–∞—è –¥–µ—Ñ–∏—Å—ã –≤–Ω—É—Ç—Ä–∏ –Ω–∞–∑–≤–∞–Ω–∏–π
        name = re.split(r'\s+[-‚Äî]\s*|\s+\(', feed_title)[0].strip()
    else:
        domain = urlparse(link).netloc.lower().replace('www.', '')
        name = domain.split('.')[0].capitalize()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ë–Å –∏ —É–±–∏—Ä–∞–µ–º –≤—Å—ë –ª–∏—à–Ω–µ–µ
    clean = "".join(re.findall(r'[a-zA-Z–∞-—è–ê-–Ø—ë–Å0-9]+', name))
    return f"#{clean}"

def process_item(item, api_name, is_ai):
    link = item.get('alternate', [{}])[0].get('href', '')
    feed_title = item.get('origin', {}).get('title', 'Source')
    domain = urlparse(link).netloc.lower()
    is_tg, is_yt = "t.me" in domain, any(x in domain for x in ["youtube.com", "youtu.be"])

    full_text, has_v, link = extract_content(item, is_tg, is_yt)
    tag = get_hashtag(feed_title, link, (is_tg or is_yt))
    v_mark = "üé¨ " if (has_v and not is_yt) else ""

    if is_ai:
        summary = call_ai(api_name, full_text)
        content = summary if summary else item.get('title')
        # –í–µ—Å—å —Ç–µ–∫—Å—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∫—É—Ä—Å–∏–≤–æ–º
        line = f"üìå <a href='{link}'>‚Üí</a> <i>{content}</i> {v_mark}\nüè∑Ô∏è {tag}"
    else:
        line = f"üìå <a href='{link}'>{item.get('title')}</a>\nüè∑Ô∏è {tag}"
    return {"id": item.get('id'), "line": line, "is_yt": is_yt}

def mark_read(api_base, headers, ids):
    if not ids: return
    try:
        data = [('i', i_id) for i_id in ids]
        data.append(('a', 'user/-/state/com.google/read'))
        requests.post(f"{api_base}/edit-tag", headers=headers, data=data, timeout=20)
    except: pass

def process_category(cat_name, use_ai, headers, api_base):
    log(f"üöÄ –ö–ê–¢–ï–ì–û–†–ò–Ø: {cat_name.upper()}")
    try:
        r = requests.get(f"{api_base}/stream/contents/user/-/label/{cat_name}",
                        params={'n': 50, 'xt': 'user/-/state/com.google/read'}, headers=headers, timeout=20)
        items = r.json().get('items', [])
    except: return
    if not items: return
    final_results = []
    if use_ai:
        active_apis = [a for a in ["groq", "mistral", "cohere"] if KEYS.get(a)]
        chunks = [items[i::len(active_apis)] for i in range(len(active_apis))]
        with ThreadPoolExecutor(max_workers=3) as ex:
            futures = [ex.submit(lambda c, a: [process_item(it, a, True) for it in c], chunks[i], active_apis[i])
                       for i in range(len(chunks)) if chunks[i]]
            for f in as_completed(futures): final_results.extend(f.result())
    else: final_results = [process_item(it, "direct", False) for it in items]

    cat_tag = f"#{cat_name.replace(' ', '')}"
    msg, ids_to_mark = ("" if cat_tag.lower() == "#youtube" else f"{cat_tag}\n\n"), []

    for entry in final_results:
        if not use_ai or entry.get('is_yt'):
            if requests.post(f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
                             json={"chat_id": CHAT_ID, "text": entry['line'], "parse_mode": "HTML",
                                   "link_preview_options": {"show_above_text": True}}).status_code == 200:
                mark_read(api_base, headers, [entry['id']])
            continue
        if len(msg) + len(entry['line']) > 4000:
            if requests.post(f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
                             json={"chat_id": CHAT_ID, "text": msg.strip(), "parse_mode": "HTML", "link_preview_options": {"is_disabled": True}}).status_code == 200:
                mark_read(api_base, headers, ids_to_mark)
            msg, ids_to_mark = f"{cat_tag}\n\n", []
        msg += entry['line'] + "\n\n"
        ids_to_mark.append(entry['id'])

    if ids_to_mark and msg:
        if requests.post(f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
                         json={"chat_id": CHAT_ID, "text": msg.strip(), "parse_mode": "HTML", "link_preview_options": {"is_disabled": True}}).status_code == 200:
            mark_read(api_base, headers, ids_to_mark)

def main():
    log("üèÅ –ó–ê–ü–£–°–ö")
    try:
        auth_res = requests.get(f"{BASE_URL}/api/greader.php/accounts/ClientLogin?Email={USER}&Passwd={PASS}", timeout=20)
        auth = re.search(r'Auth=(.*)', auth_res.text)
        if not auth: return
        headers = {'Authorization': f'GoogleLogin auth={auth.group(1).strip()}'}
        api_base = f"{BASE_URL}/api/greader.php/reader/api/0"
        for cat in CATEGORIES_AI: process_category(cat, True, headers, api_base)
        for cat in CATEGORIES_DIRECT: process_category(cat, False, headers, api_base)
        log("‚úÖ –ì–û–¢–û–í–û")
    except Exception as e: log(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__": main()
