#!/usr/bin/env python3
import requests
import json
import os
import time
from bs4 import BeautifulSoup

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
BASE_URL = os.getenv("FRESHRSS_URL", "").rstrip('/')
USER = os.getenv("FRESHRSS_USER")
PASS = os.getenv("FRESHRSS_PASS")
OPENROUTER_KEY = os.getenv("OPENROUTER_KEY")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")

CATEGORIES = {
    "–ù–∞—É—á–ø–æ–ø": "üî≠",
    "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏": "üíª",
    "–ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∂–µ–ª–µ–∑–æ": "‚öôÔ∏è"
}

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π, –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –Ω–∞ 2026 –≥–æ–¥
AI_MODELS = [
    "google/gemini-2.0-flash-001",
    "google/gemini-2.0-flash-exp:free",
    "qwen/qwen-2.5-72b-instruct",
    "deepseek/deepseek-chat",
    "meta-llama/llama-3.3-70b-instruct",
    "mistralai/mistral-small-24b-instruct-2501"
]

def log(message):
    print(f"[{time.strftime('%H:%M:%S')}] {message}")

def get_auth_token():
    url = f"{BASE_URL}/api/greader.php/accounts/ClientLogin"
    try:
        r = requests.get(url, params={'Email': USER, 'Passwd': PASS}, timeout=10)
        if r.status_code == 200:
            for line in r.text.split('\n'):
                if line.startswith('Auth='): return line.replace('Auth=', '').strip()
    except: return None

def get_full_text(url):
    try:
        # –î–æ–±–∞–≤–ª—è–µ–º –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏, —á—Ç–æ–±—ã —Å–∞–π—Ç—ã –Ω–µ –±–ª–æ—á–∏–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        r = requests.get(url, headers=headers, timeout=12)
        if r.status_code != 200:
            log(f"  ‚ö†Ô∏è –°–∞–π—Ç –≤–µ—Ä–Ω—É–ª –∫–æ–¥ {r.status_code}")
            return ""

        soup = BeautifulSoup(r.text, 'html.parser')
        for s in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'button', 'form']): s.decompose()

        article = (
            soup.find('div', {'class': 'tm-article-body'}) or # Habr
            soup.find('div', {'class': 'article-content'}) or
            soup.find('article') or soup.find('main')
        )
        text = article.get_text(separator=' ', strip=True) if article else soup.get_text(separator=' ', strip=True)
        return " ".join(text.split())[:5000]
    except Exception as e:
        log(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
        return ""

def get_ai_summary(url, seen_summaries):
    content = get_full_text(url)
    if len(content) < 200:
        log("  ‚ö†Ô∏è –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
        return None

    prompt = (
        "–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ä–µ–¥–∞–∫—Ç–æ—Ä. –¢–≤–æ—è –∑–∞–¥–∞—á–∞: –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∏–∂–µ –∏ –Ω–∞–ø–∏—Å–∞—Ç—å –û–î–ù–û –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ (–¥–æ 15 —Å–ª–æ–≤) –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ, "
        "–∫–æ—Ç–æ—Ä–æ–µ –≤—ã—Ä–∞–∂–∞–µ—Ç –≥–ª–∞–≤–Ω—É—é —Å—É—Ç—å –Ω–æ–≤–æ—Å—Ç–∏. –ò–≥–Ω–æ—Ä–∏—Ä—É–π –∑–∞–≥–æ–ª–æ–≤–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–∞. "
        "–ï—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç—å –¥—É–±–ª–∏—Ä—É–µ—Ç —ç—Ç–∏ —Ç–µ–º—ã, –æ—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–æ–º –î–£–ë–õ–ò–ö–ê–¢: " + ", ".join(list(seen_summaries)[-5:]) + ". "
        f"\n\n–¢–ï–ö–°–¢ –°–¢–ê–¢–¨–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:\n{content[:4000]}"
    )

    for model in AI_MODELS:
        try:
            log(f"    ü§ñ –ó–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏: {model}...")
            r = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {OPENROUTER_KEY}",
                    "Content-Type": "application/json",
                    "X-Title": "News Summary Bot"
                },
                data=json.dumps({
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.1
                }),
                timeout=30
            )

            if r.status_code == 200:
                res = r.json()['choices'][0]['message']['content'].strip()
                if "–î–£–ë–õ–ò–ö–ê–¢" in res.upper(): return "SKIP"
                log("    ‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑.")
                return res.rstrip('.')
            else:
                log(f"    ‚ùå –û—à–∏–±–∫–∞ API ({r.status_code}): {r.text[:200]}")
        except Exception as e:
            log(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ {model}: {e}")
            continue
    return None

def clean_hashtag(name):
    name_low = name.lower()
    # –°–ø–µ—Ü—É—Å–ª–æ–≤–∏–µ –¥–ª—è –•–∞–±—Ä–∞
    if 'habr' in name_low or '—Ö–∞–±—Ä' in name_low: return "#habr"

    for junk in ['–Ω–æ–≤–æ—Å—Ç–∏', 'news', '–ª–µ–Ω—Ç–∞', 'feed', '—Å—Ç–∞—Ç—å–∏', '–±–ª–æ–≥', '–ø–æ–¥—Ä—è–¥']:
        name_low = name_low.replace(junk, '')
    clean = "".join(filter(str.isalnum, name_low))
    return f"#{clean}" if clean else "#–Ω–æ–≤–æ—Å—Ç–∏"

def main():
    log("=== –ó–ê–ü–£–°–ö: –û–¢–õ–ê–î–ö–ê –ò–ò-–ê–ì–ï–ù–¢–û–í ===")
    token = get_auth_token()
    if not token:
        log("‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –≤–æ FreshRSS. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏–Ω/–ø–∞—Ä–æ–ª—å.")
        return

    headers = {'Authorization': f'GoogleLogin auth={token}'}
    api_base = f"{BASE_URL}/api/greader.php/reader/api/0"
    global_seen_summaries = set()

    for cat, emoji in CATEGORIES.items():
        log(f"\nüìÅ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {cat}")
        try:
            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏
            r = requests.get(f"{api_base}/stream/contents/user/-/label/{cat}",
                             params={'xt': 'user/-/state/com.google/read', 'n': 10}, headers=headers)
            items = r.json().get('items', [])

            if items:
                msg = f"<b>{emoji} {cat.upper()}:</b>\n\n"
                count = 0
                for item in items:
                    link = item.get('alternate', [{}])[0].get('href', '')
                    source = item.get('origin', {}).get('title', 'news')
                    log(f"üëâ –û–±—Ä–∞–±–æ—Ç–∫–∞: {item.get('title', '')[:60]}...")

                    summary = get_ai_summary(link, global_seen_summaries)

                    if summary == "SKIP":
                        log("    üö´ –î—É–±–ª–∏–∫–∞—Ç –ø–æ —Å–º—ã—Å–ª—É. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                    elif summary:
                        global_seen_summaries.add(summary)
                        tag = clean_hashtag(source)
                        # –§–æ—Ä–º–∞—Ç: üìå –°—É—Ç—å üîó #—Ç–µ–≥
                        msg += f"üìå {summary} üîó <a href='{link}'>{tag}</a>\n\n"
                        count += 1
                    else:
                        log("    ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é –Ω–∏ –æ—Ç –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏.")

                    # –í—Å–µ–≥–¥–∞ –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω–æ–µ
                    requests.post(f"{api_base}/edit-tag", headers=headers, data={'i': item.get('id'), 'a': 'user/-/state/com.google/read'})

                if count > 0:
                    tg_r = requests.post(f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
                                  data={"chat_id": CHAT_ID, "text": msg, "parse_mode": "HTML", "disable_web_page_preview": True})
                    if tg_r.status_code == 200:
                        log(f"‚úÖ –î–∞–π–¥–∂–µ—Å—Ç {cat} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Telegram.")
                    else:
                        log(f"‚ùå –û—à–∏–±–∫–∞ Telegram: {tg_r.text}")
            else:
                log("  –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π.")
        except Exception as e:
            log(f"  –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {cat}: {e}")

if __name__ == "__main__":
    main()
